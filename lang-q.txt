# Neural-Language Query Commands

## Basic Commands

# Get neural windows for written language (W) with default parameters (gpt2 tokenizer, 10s pre-window)
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group W

# Get neural windows for listened language (L)
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group L

# Get neural windows for read language (R)
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group R

# Get neural windows for spoken language (S)
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group S

# Get neural windows for corrected written language (W_corrected)
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group W_corrected

## Tokenizer Variations

# Use a different tokenizer (if available in your data)
python -m data_pipeline.cli t4A_query --neuro-lang --tokenizer llama

# Use facebook/opt-125m tokenizer
python -m data_pipeline.cli t4A_query --neuro-lang --tokenizer facebook/opt-125m

## Time Window Variations

# Get 5 seconds of neural data before each token
python -m data_pipeline.cli t4A_query --neuro-lang --pre-window-seconds 5

# Get 2 seconds of neural data before each token
python -m data_pipeline.cli t4A_query --neuro-lang --pre-window-seconds 2

# Get 30 seconds of neural data before each token
python -m data_pipeline.cli t4A_query --neuro-lang --pre-window-seconds 30

## Combined Parameters

# Get listened language (L) with gpt2 tokenizer and 5s pre-window
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group L --tokenizer gpt2 --pre-window-seconds 5

# Get written language (W) with facebook/opt-125m tokenizer and 3s pre-window
python -m data_pipeline.cli t4A_query --neuro-lang --lang-group W --tokenizer facebook/opt-125m --pre-window-seconds 3

## AWS Options

# Use a different S3 bucket
python -m data_pipeline.cli t4A_query --neuro-lang --s3-bucket your-bucket-name

# Use a different source prefix
python -m data_pipeline.cli t4A_query --neuro-lang --source-prefix processed/your-event-prefix/

## Debug Options

# Enable verbose logging
python -m data_pipeline.cli t4A_query --neuro-lang --verbose

# Run in dry-run mode (test without saving data)
python -m data_pipeline.cli t4A_query --neuro-lang --dry-run

# Keep local files after running (helpful for troubleshooting)
python -m data_pipeline.cli t4A_query --neuro-lang --keep-local

# Test mode (combines dry-run and keep-local)
python -m data_pipeline.cli t4A_query --neuro-lang --test